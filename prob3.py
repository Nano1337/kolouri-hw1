import numpy as np
import matplotlib.pyplot as plt
from scipy.interpolate import interp1d

def gaussian_kernel(x, mu, sigma): 
    return np.exp(-((x - mu)**2 / (2*sigma**2)))

def make_design_matrix(x, means, sigma):
    """
    Purpose: make N x M matrix: 
    - N is # of data samples
    - M is number of features given by Gaussian kernels
    """

    X = np.zeros((x.shape[0], x.shape[1], len(means)))

    # apply Gaussian kernels to create design matrix
    for i, mean in enumerate(means): 
        X[:, :, i] = gaussian_kernel(x, mean, sigma)

    return X

def main(data, gt, M): 
    interp_fxn = interp1d(gt[0, :], gt[1, :], kind='linear')

    print(data.shape, gt.shape)

    x = data[:, :, 0]
    y = data[:, :, 1]

    mu = np.linspace(-5, 5, M+2)[1:-1]
    s = 2 / (M+1)
    X = make_design_matrix(x, mu, s)

    # closed form solver with MSE
    weights = np.zeros((x.shape[0], M))
    for i in range(x.shape[0]):
        weights[i] = np.linalg.inv(X[i].T @ X[i]) @ X[i].T @ y[i]
    
    # make a 2x5 plot of the learned functions and their x, y data
    plt.figure(figsize=(17, 6))  # Increase the width from 20 to 24
    for i in range(x.shape[0]):
        # Sort x values and use the same order for y values generated by the learned function
        sorted_indices = np.argsort(x[i])
        sorted_x = x[i][sorted_indices]
        sorted_y = (X[i][sorted_indices] @ weights[i])  # Assuming X[i] can be indexed like this

        plt.subplot(2, 5, i+1)
        plt.scatter(x[i], y[i], label='Data')
        plt.plot(sorted_x, sorted_y, label='Learned Function', color='red')
        plt.plot(gt[0], gt[1], label='Ground Truth', color='green')    
    plt.savefig(f"prob3_learned_functions_M{M}.png")

    biases = []
    variances = []

    # Plotting and collecting predictions for bias/variance calculation
    plt.figure(figsize=(17, 6))
    for i in range(x.shape[0]):  # Assuming x.shape[0] is the number of datasets
        sorted_indices = np.argsort(x[i])
        sorted_x = x[i][sorted_indices]
        avg_sorted_y = X[i][sorted_indices] @ weights.T  # Compute predictions for each model
        sorted_y = np.mean(avg_sorted_y, axis=1)  # Average prediction for the current dataset

        # calculate bias and variance within each dataset
        y_true = interp_fxn(sorted_x)
        biases.append(np.mean(np.absolute(y_true - sorted_y)))
        variances.append(np.var(sorted_y))

        plt.subplot(2, 5, i+1)
        plt.scatter(x[i], y[i], label='Data')
        plt.plot(sorted_x, sorted_y, label='Learned Function', color='red')
        plt.plot(gt[0], gt[1], label='Ground Truth', color='green')

    plt.savefig(f"prob3_avg_learned_functions_M{M}.png")

    bias, var = np.mean(np.array(biases)), np.mean(np.array(variances))

    print(f"Bias: {bias:.4f}, Variance: {var:.4f}")

    # calculate weights with ridge regression
    lambdan = 0.1
    weights = np.zeros((x.shape[0], M))
    for i in range(x.shape[0]):
        weights[i] = np.linalg.inv(X[i].T @ X[i] + lambdan * np.eye(M)) @ X[i].T @ y[i]

    # make a 2x5 plot of the learned functions and their x, y data
    plt.figure(figsize=(17, 6))  # Increase the width from 20 to 24
    for i in range(x.shape[0]):
        # Sort x values and use the same order for y values generated by the learned function
        sorted_indices = np.argsort(x[i])
        sorted_x = x[i][sorted_indices]
        sorted_y = (X[i][sorted_indices] @ weights[i])  # Assuming X[i] can be indexed like this

        plt.subplot(2, 5, i+1)
        plt.scatter(x[i], y[i], label='Data')
        plt.plot(sorted_x, sorted_y, label='Learned Function', color='red')
        plt.plot(gt[0], gt[1], label='Ground Truth', color='green')
    plt.savefig(f"prob3_ridge_learned_functions_M{M}.png")

    biases = []
    variances = []

    # average predictions
    plt.figure(figsize=(17, 6))
    for i in range(x.shape[0]):
        sorted_indices = np.argsort(x[i])
        sorted_x = x[i][sorted_indices]
        avg_sorted_y = X[i][sorted_indices] @ weights.T
        sorted_y = np.mean(avg_sorted_y, axis=1)

        # calculate bias and variance within each dataset
        y_true = interp_fxn(sorted_x)
        biases.append(np.mean(np.absolute(y_true - sorted_y)))
        variances.append(np.var(sorted_y))

        plt.subplot(2, 5, i+1)
        plt.scatter(x[i], y[i], label='Data')
        plt.plot(sorted_x, sorted_y, label='Learned Function', color='red')
        plt.plot(gt[0], gt[1], label='Ground Truth', color='green')
    plt.savefig(f"prob3_ridge_avg_learned_functions_M{M}.png")

    bias, var = np.mean(np.array(biases)), np.mean(np.array(variances))

    print(f"Bias: {bias:.4f}, Variance: {var:.4f}")


if __name__ == "__main__": 
    
    data = np.load('hw1_p3.npy')
    gt = np.load('hw1_p3_gt.npy')

    M = 21
    main(data, gt, M)